# ASL Recognition Model

American Sign Language (ASL) recognition system using MediaPipe landmarks and deep learning.

## ğŸ“ Project Structure

```
asl_model/
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ config.yaml              # Main configuration
â”‚   â””â”€â”€ label_map.json           # Label normalization rules
â”œâ”€â”€ data/                        # Raw datasets
â”‚   â”œâ”€â”€ kaggle_asl_combined/    # Combined Kaggle ASL images
â”‚   â”œâ”€â”€ microsoft_asl/          # MS-ASL videos and metadata
â”‚   â””â”€â”€ personal/               # Personal recordings (optional)
â”œâ”€â”€ artifacts/                   # Generated artifacts
â”‚   â”œâ”€â”€ landmarks/              # Raw MediaPipe landmarks [T, 543, 4]
â”‚   â”œâ”€â”€ features/               # Preprocessed features [T, 75, 4]
â”‚   â”œâ”€â”€ manifests/              # Dataset manifests (CSV)
â”‚   â”œâ”€â”€ models/                 # Trained model checkpoints
â”‚   â””â”€â”€ logs/                   # Training logs
â”œâ”€â”€ src/                        # Core library code
â”‚   â”œâ”€â”€ data/                   # Data processing modules
â”‚   â”‚   â””â”€â”€ dataloader.py      # PyTorch dataloader
â”‚   â””â”€â”€ utils/                  # Utility functions
â”œâ”€â”€ scripts/                    # Executable scripts
â”‚   â”œâ”€â”€ 1_data_preparation/    # Download and organize data
â”‚   â”œâ”€â”€ 2_preprocessing/       # Extract and preprocess features
â”‚   â”œâ”€â”€ 3_training/            # Train models
â”‚   â””â”€â”€ 4_evaluation/          # Test and visualize
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/davidgit3000/asl_recognition.git
cd asl_recognition
```

### 2. Setup Environment

**Mac/Linux:**
```bash
# Create virtual environment
python3.11 -m venv .venv311
source .venv311/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Windows:**
```bash
# Create virtual environment
python -m venv .venv311
.venv311\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Download Datasets

**Kaggle Datasets (required):**

Option A - Using script (Mac/Linux):
```bash
# Setup Kaggle API credentials first (~/.kaggle/kaggle.json)
bash download_kaggle_datasets.sh
```

Option B - Manual download:
- Download [ASL Alphabet](https://www.kaggle.com/datasets/grassknoted/asl-alphabet) â†’ extract to `data/kaggle_asl1/`
- Download [ASL Dataset](https://www.kaggle.com/datasets/ayuraj/asl-dataset) â†’ extract to `data/kaggle_asl2/`

**MS-ASL Videos (optional):**
- Download from [MS-ASL Dataset](https://microsoft.github.io/data-for-society/dataset?d=MS-ASL-American-Sign-Language-Dataset#overview)
- Then, use automated scripts (see `scripts/1_data_preparation/README.md`)

### 4. Prepare Data

```bash
# Combine Kaggle datasets
python scripts/1_data_preparation/combine_kaggle_asl.py

# Build manifest and assign splits
python scripts/1_data_preparation/build_manifest.py
python scripts/1_data_preparation/assign_splits.py
```

### 5. Extract and Preprocess Features

```bash
# Extract MediaPipe landmarks
python scripts/2_preprocessing/extract_landmarks.py

# Preprocess features for training
python scripts/2_preprocessing/preprocess_features.py
```

### 6. Test Dataloader

```bash
python scripts/4_evaluation/test_dataloader_with_splits.py
```

## ğŸ“Š Dataset

- **Kaggle ASL Alphabet**: ~26,000 images (A-Z letters)
- **MS-ASL**: ~190 videos (20 common words)
- **Total**: 26,190 samples, 45 classes
- **Splits**: 70% train, 15% val, 15% test (stratified)

## ğŸ”§ Pipeline Overview

1. **Data Collection** â†’ Download Kaggle + MS-ASL datasets
2. **Manifest Building** â†’ Create unified CSV with metadata
3. **Landmark Extraction** â†’ MediaPipe Holistic (543 landmarks)
4. **Feature Preprocessing** â†’ Normalize, smooth, reduce to 75 landmarks
5. **Train/Val/Test Split** â†’ Stratified 70/15/15 split
6. **Dataloader** â†’ PyTorch DataLoader with windowing
7. **Training** â†’ Train ASL recognition model (to be implemented)
8. **Evaluation** â†’ Test and visualize results

## ğŸ“¦ Features

- âœ… MediaPipe Holistic landmark extraction
- âœ… Temporal smoothing (Savitzky-Golay filter)
- âœ… Normalization (centered on torso, scaled by shoulder width)
- âœ… Windowed sequences (32 frames by default)
- âœ… Data augmentation (rotation, scale, translation)
- âœ… Class balancing (weighted loss for imbalanced data)
- âœ… Stratified train/val/test splits

## ğŸ“ Documentation

- `KAGGLE_DATASETS_INFO.md` - Kaggle dataset details
- `MSASL_PIPELINE.md` - MS-ASL download pipeline
- `scripts/README.md` - Scripts documentation
- `scripts/*/README.md` - Detailed docs for each stage

## ğŸ¯ Next Steps

1. Implement baseline model (LSTM/Transformer)
2. Train and evaluate
3. Build real-time inference pipeline
4. Create webcam demo

## ğŸ“„ License

Educational project for CS 4620.
